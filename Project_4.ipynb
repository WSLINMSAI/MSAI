{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzDou9mn3MdEx2Xu5dR9ng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSLINMSAI/MSAI-531-B01/blob/main/Project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install dependencies\n",
        "!pip install nltk ipywidgets jieba langdetect regex --quiet"
      ],
      "metadata": {
        "id": "NKJK3_T9UFpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 2: Import libraries and download NLTK resources\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "aF_oYv9VUFre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 3: Import supporting modules\n",
        "import jieba\n",
        "from langdetect import detect\n",
        "import re\n",
        "import math\n",
        "from nltk.corpus import brown, words as nltk_words\n",
        "from nltk import FreqDist, bigrams\n",
        "from collections import defaultdict\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import base64"
      ],
      "metadata": {
        "id": "8xDoPlKuUIrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 4: Load corpora and create word lists\n",
        "brown_words = [w.lower() for w in brown.words() if w.isalpha()]\n",
        "english_vocab = set(w.lower() for w in nltk_words.words())"
      ],
      "metadata": {
        "id": "odRR_XQmULHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 5: Build unigram and bigram frequency models\n",
        "unigram_freq = FreqDist(brown_words)\n",
        "total_unigrams = sum(unigram_freq.values())\n",
        "\n",
        "unigram_probs = {\n",
        "    word: math.log(freq / total_unigrams)\n",
        "    for word, freq in unigram_freq.items()\n",
        "}\n",
        "\n",
        "bigram_freq = FreqDist(bigrams(brown_words))\n",
        "bigram_probs = {\n",
        "    (w1, w2): math.log(freq / unigram_freq[w1])\n",
        "    for (w1, w2), freq in bigram_freq.items()\n",
        "    if unigram_freq[w1] > 0\n",
        "}"
      ],
      "metadata": {
        "id": "bxxE0RAeUL3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 6: Probability scoring functions\n",
        "def unigram_log_prob(word):\n",
        "    if word in unigram_probs:\n",
        "        return unigram_probs[word]\n",
        "    elif word in english_vocab:\n",
        "        return math.log(1e-6)\n",
        "    else:\n",
        "        return -10 * len(word)\n",
        "\n",
        "def bigram_log_prob(prev, word):\n",
        "    if (prev, word) in bigram_probs:\n",
        "        return bigram_probs[(prev, word)]\n",
        "    else:\n",
        "        return unigram_log_prob(word)"
      ],
      "metadata": {
        "id": "b9ruj8DsUNcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 7: English bigram segmentation using Viterbi\n",
        "def segment_bigram(text):\n",
        "    n = len(text)\n",
        "    best_score = [float('inf')] * (n + 1)\n",
        "    backtrack = [0] * (n + 1)\n",
        "    words_at = [''] * (n + 1)\n",
        "    prev_words = [''] * (n + 1)\n",
        "\n",
        "    best_score[0] = 0\n",
        "    words_at[0] = ''\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(max(0, i - 25), i):\n",
        "            word = text[j:i]\n",
        "            prev = words_at[j] if j > 0 else '<s>'\n",
        "            score = best_score[j] + (-bigram_log_prob(prev, word))\n",
        "            if score < best_score[i]:\n",
        "                best_score[i] = score\n",
        "                backtrack[i] = j\n",
        "                words_at[i] = word\n",
        "                prev_words[i] = prev\n",
        "\n",
        "    i = n\n",
        "    segments = []\n",
        "    while i > 0:\n",
        "        j = backtrack[i]\n",
        "        word = text[j:i]\n",
        "        prev = prev_words[i] if j > 0 else '<s>'\n",
        "        score = -bigram_log_prob(prev, word)\n",
        "        segments.append((word, score))\n",
        "        i = j\n",
        "\n",
        "    segments.reverse()\n",
        "    return segments"
      ],
      "metadata": {
        "id": "CKsAWTmHUPIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 8: Mixed-language processor using regex\n",
        "\n",
        "def process_mixed_language(text):\n",
        "    tokens = re.findall(r'[\\u4e00-\\u9fff]+|[a-zA-Z]+', text)\n",
        "    output = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if re.match(r'^[\\u4e00-\\u9fff]+$', token):\n",
        "            output.extend([(w, 'zh') for w in jieba.cut(token)])\n",
        "        elif token.isalpha():\n",
        "            segs = segment_bigram(token)\n",
        "            output.extend([(w, s) for w, s in segs])\n",
        "        else:\n",
        "            output.append((token, 'unknown'))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7UYi2IUtURYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 9: Define confidence-based color coding\n",
        "\n",
        "def get_color(score):\n",
        "    if score < 5:\n",
        "        return 'green'\n",
        "    elif score < 10:\n",
        "        return 'orange'\n",
        "    else:\n",
        "        return 'red'"
      ],
      "metadata": {
        "id": "PqFJx1nwUTJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 10: Interactive widget to display segmentation\n",
        "text_input = widgets.Text(\n",
        "    value='machinelearning正在重新定义教育healthcare和transportation领域的解决方案和效率',\n",
        "    placeholder='Enter English, Chinese, or mixed text',\n",
        "    description='Input:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(change):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        user_input = text_input.value.strip()\n",
        "        if not user_input:\n",
        "            print(\"❌ Please enter non-empty text.\")\n",
        "            return\n",
        "\n",
        "        result = process_mixed_language(user_input)\n",
        "        scores = [s for _, s in result if isinstance(s, float)]\n",
        "        avg_score = sum(scores) / len(scores) if scores else 0\n",
        "        high_conf = sum(1 for s in scores if s < 5)\n",
        "\n",
        "        display(HTML(\"<h3>✅ Mixed-language Segmentation</h3>\"))\n",
        "\n",
        "        html = \"\"\"\n",
        "        <style>\n",
        "        table { border-collapse: collapse; margin-top: 10px; }\n",
        "        th, td { border: 1px solid #ccc; padding: 6px 12px; text-align: left; }\n",
        "        th { background-color: #f2f2f2; }\n",
        "        .green { color: green; font-weight: bold; }\n",
        "        .orange { color: orange; font-weight: bold; }\n",
        "        .red { color: red; font-weight: bold; }\n",
        "        .blue { color: blue; font-weight: bold; }\n",
        "        </style>\n",
        "        <table>\n",
        "        <tr><th>Word</th><th>Score</th><th>Confidence</th><th>Language</th></tr>\n",
        "        \"\"\"\n",
        "\n",
        "        for word, info in result:\n",
        "            if isinstance(info, str) and info == 'zh':\n",
        "                html += f\"<tr><td class='blue'>{word}</td><td>–</td><td>–</td><td>Chinese</td></tr>\"\n",
        "            elif isinstance(info, float):\n",
        "                color = get_color(info)\n",
        "                explanation = (\n",
        "                    \"High confidence\" if color == 'green' else\n",
        "                    \"Moderate confidence\" if color == 'orange' else\n",
        "                    \"Low confidence\"\n",
        "                )\n",
        "                html += f\"<tr><td class='{color}'>{word}</td><td>{info:.3f}</td><td>{explanation}</td><td>English</td></tr>\"\n",
        "            else:\n",
        "                html += f\"<tr><td>{word}</td><td>–</td><td>Unknown</td><td>Unknown</td></tr>\"\n",
        "\n",
        "        html += \"</table>\"\n",
        "        display(HTML(html))\n",
        "\n",
        "        summary = f\"<p><b>Summary:</b> {len(scores)} English words, {high_conf} high-confidence. Avg. score = {avg_score:.3f}</p>\"\n",
        "        display(HTML(summary))\n",
        "        print(\"\\nNote: English words use a bigram model trained on the Brown corpus. Chinese words use jieba.\")\n"
      ],
      "metadata": {
        "id": "f6M8nqCIUWs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 11: Launch the interface\n",
        "text_input.on_submit(on_submit)\n",
        "display(text_input, output_area)"
      ],
      "metadata": {
        "id": "tNqErPn0Ual3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}