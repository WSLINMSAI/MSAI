{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzDou9mn3MdEx2Xu5dR9ng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b693262f177b4ddba9ad3b7c11a4a270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Input:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_710778c9732b4e13968f70d03a8bd6ed",
            "placeholder": "Enter English, Chinese, or mixed text",
            "style": "IPY_MODEL_0cbd76ece81f4cac9d95bf9302a53585",
            "value": "machinelearning正在重新定义教育healthcare和transportation领域的解决方案和效率"
          }
        },
        "710778c9732b4e13968f70d03a8bd6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0cbd76ece81f4cac9d95bf9302a53585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a297b452d46748a1a92e9c44bdd790a0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_82ba355c90ed4c91ad00899e5d148a78",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Building prefix dict from the default dictionary ...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "DEBUG:jieba:Building prefix dict from the default dictionary ...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Dumping model to file cache /tmp/jieba.cache\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Loading model cost 0.636 seconds.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "DEBUG:jieba:Loading model cost 0.636 seconds.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Prefix dict has been built successfully.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "DEBUG:jieba:Prefix dict has been built successfully.\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<h3>✅ Mixed-language Segmentation</h3>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "\n        <style>\n        table { border-collapse: collapse; margin-top: 10px; }\n        th, td { border: 1px solid #ccc; padding: 6px 12px; text-align: left; }\n        th { background-color: #f2f2f2; }\n        .green { color: green; font-weight: bold; }\n        .orange { color: orange; font-weight: bold; }\n        .red { color: red; font-weight: bold; }\n        .blue { color: blue; font-weight: bold; }\n        </style>\n        <table>\n        <tr><th>Word</th><th>Score</th><th>Confidence</th><th>Language</th></tr>\n        <tr><td class='orange'>machine</td><td>9.162</td><td>Moderate confidence</td><td>English</td></tr><tr><td class='orange'>learning</td><td>9.703</td><td>Moderate confidence</td><td>English</td></tr><tr><td class='blue'>正在</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>重新</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>定义</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>教育</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='orange'>health</td><td>9.143</td><td>Moderate confidence</td><td>English</td></tr><tr><td class='green'>care</td><td>3.961</td><td>High confidence</td><td>English</td></tr><tr><td class='blue'>和</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='red'>transportation</td><td>10.036</td><td>Low confidence</td><td>English</td></tr><tr><td class='blue'>领域</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>的</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>解决方案</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>和</td><td>–</td><td>–</td><td>Chinese</td></tr><tr><td class='blue'>效率</td><td>–</td><td>–</td><td>Chinese</td></tr></table>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p><b>Summary:</b> 5 English words, 1 high-confidence. Avg. score = 8.401</p>"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  "Note: English words use a bigram model trained on the Brown corpus. Chinese words use jieba.\n"
                ]
              }
            ]
          }
        },
        "82ba355c90ed4c91ad00899e5d148a78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSLINMSAI/MSAI-531-B01/blob/main/Project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install dependencies\n",
        "!pip install nltk ipywidgets jieba langdetect regex --quiet"
      ],
      "metadata": {
        "id": "NKJK3_T9UFpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dcfadd-7766-48a4-ec9c-ae469fc65350"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.3/981.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 2: Import libraries and download NLTK resources\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF_oYv9VUFre",
        "outputId": "b73bc6e2-6e6a-4be5-9955-219ec69f5083"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 3: Import supporting modules\n",
        "import jieba\n",
        "from langdetect import detect\n",
        "import re\n",
        "import math\n",
        "from nltk.corpus import brown, words as nltk_words\n",
        "from nltk import FreqDist, bigrams\n",
        "from collections import defaultdict\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import base64"
      ],
      "metadata": {
        "id": "8xDoPlKuUIrc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 4: Load corpora and create word lists\n",
        "brown_words = [w.lower() for w in brown.words() if w.isalpha()]\n",
        "english_vocab = set(w.lower() for w in nltk_words.words())"
      ],
      "metadata": {
        "id": "odRR_XQmULHM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 5: Build unigram and bigram frequency models\n",
        "unigram_freq = FreqDist(brown_words)\n",
        "total_unigrams = sum(unigram_freq.values())\n",
        "\n",
        "unigram_probs = {\n",
        "    word: math.log(freq / total_unigrams)\n",
        "    for word, freq in unigram_freq.items()\n",
        "}\n",
        "\n",
        "bigram_freq = FreqDist(bigrams(brown_words))\n",
        "bigram_probs = {\n",
        "    (w1, w2): math.log(freq / unigram_freq[w1])\n",
        "    for (w1, w2), freq in bigram_freq.items()\n",
        "    if unigram_freq[w1] > 0\n",
        "}"
      ],
      "metadata": {
        "id": "bxxE0RAeUL3F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 6: Probability scoring functions\n",
        "def unigram_log_prob(word):\n",
        "    if word in unigram_probs:\n",
        "        return unigram_probs[word]\n",
        "    elif word in english_vocab:\n",
        "        return math.log(1e-6)\n",
        "    else:\n",
        "        return -10 * len(word)\n",
        "\n",
        "def bigram_log_prob(prev, word):\n",
        "    if (prev, word) in bigram_probs:\n",
        "        return bigram_probs[(prev, word)]\n",
        "    else:\n",
        "        return unigram_log_prob(word)"
      ],
      "metadata": {
        "id": "b9ruj8DsUNcc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 7: English bigram segmentation using Viterbi\n",
        "def segment_bigram(text):\n",
        "    n = len(text)\n",
        "    best_score = [float('inf')] * (n + 1)\n",
        "    backtrack = [0] * (n + 1)\n",
        "    words_at = [''] * (n + 1)\n",
        "    prev_words = [''] * (n + 1)\n",
        "\n",
        "    best_score[0] = 0\n",
        "    words_at[0] = ''\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(max(0, i - 25), i):\n",
        "            word = text[j:i]\n",
        "            prev = words_at[j] if j > 0 else '<s>'\n",
        "            score = best_score[j] + (-bigram_log_prob(prev, word))\n",
        "            if score < best_score[i]:\n",
        "                best_score[i] = score\n",
        "                backtrack[i] = j\n",
        "                words_at[i] = word\n",
        "                prev_words[i] = prev\n",
        "\n",
        "    i = n\n",
        "    segments = []\n",
        "    while i > 0:\n",
        "        j = backtrack[i]\n",
        "        word = text[j:i]\n",
        "        prev = prev_words[i] if j > 0 else '<s>'\n",
        "        score = -bigram_log_prob(prev, word)\n",
        "        segments.append((word, score))\n",
        "        i = j\n",
        "\n",
        "    segments.reverse()\n",
        "    return segments"
      ],
      "metadata": {
        "id": "CKsAWTmHUPIu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 8: Mixed-language processor using regex\n",
        "\n",
        "def process_mixed_language(text):\n",
        "    tokens = re.findall(r'[\\u4e00-\\u9fff]+|[a-zA-Z]+', text)\n",
        "    output = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if re.match(r'^[\\u4e00-\\u9fff]+$', token):\n",
        "            output.extend([(w, 'zh') for w in jieba.cut(token)])\n",
        "        elif token.isalpha():\n",
        "            segs = segment_bigram(token)\n",
        "            output.extend([(w, s) for w, s in segs])\n",
        "        else:\n",
        "            output.append((token, 'unknown'))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7UYi2IUtURYM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 9: Define confidence-based color coding\n",
        "\n",
        "def get_color(score):\n",
        "    if score < 5:\n",
        "        return 'green'\n",
        "    elif score < 10:\n",
        "        return 'orange'\n",
        "    else:\n",
        "        return 'red'"
      ],
      "metadata": {
        "id": "PqFJx1nwUTJW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 10: Interactive widget to display segmentation\n",
        "text_input = widgets.Text(\n",
        "    value='machinelearning正在重新定义教育healthcare和transportation领域的解决方案和效率',\n",
        "    placeholder='Enter English, Chinese, or mixed text',\n",
        "    description='Input:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(change):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        user_input = text_input.value.strip()\n",
        "        if not user_input:\n",
        "            print(\"❌ Please enter non-empty text.\")\n",
        "            return\n",
        "\n",
        "        result = process_mixed_language(user_input)\n",
        "        scores = [s for _, s in result if isinstance(s, float)]\n",
        "        avg_score = sum(scores) / len(scores) if scores else 0\n",
        "        high_conf = sum(1 for s in scores if s < 5)\n",
        "\n",
        "        display(HTML(\"<h3>✅ Mixed-language Segmentation</h3>\"))\n",
        "\n",
        "        html = \"\"\"\n",
        "        <style>\n",
        "        table { border-collapse: collapse; margin-top: 10px; }\n",
        "        th, td { border: 1px solid #ccc; padding: 6px 12px; text-align: left; }\n",
        "        th { background-color: #f2f2f2; }\n",
        "        .green { color: green; font-weight: bold; }\n",
        "        .orange { color: orange; font-weight: bold; }\n",
        "        .red { color: red; font-weight: bold; }\n",
        "        .blue { color: blue; font-weight: bold; }\n",
        "        </style>\n",
        "        <table>\n",
        "        <tr><th>Word</th><th>Score</th><th>Confidence</th><th>Language</th></tr>\n",
        "        \"\"\"\n",
        "\n",
        "        for word, info in result:\n",
        "            if isinstance(info, str) and info == 'zh':\n",
        "                html += f\"<tr><td class='blue'>{word}</td><td>–</td><td>–</td><td>Chinese</td></tr>\"\n",
        "            elif isinstance(info, float):\n",
        "                color = get_color(info)\n",
        "                explanation = (\n",
        "                    \"High confidence\" if color == 'green' else\n",
        "                    \"Moderate confidence\" if color == 'orange' else\n",
        "                    \"Low confidence\"\n",
        "                )\n",
        "                html += f\"<tr><td class='{color}'>{word}</td><td>{info:.3f}</td><td>{explanation}</td><td>English</td></tr>\"\n",
        "            else:\n",
        "                html += f\"<tr><td>{word}</td><td>–</td><td>Unknown</td><td>Unknown</td></tr>\"\n",
        "\n",
        "        html += \"</table>\"\n",
        "        display(HTML(html))\n",
        "\n",
        "        summary = f\"<p><b>Summary:</b> {len(scores)} English words, {high_conf} high-confidence. Avg. score = {avg_score:.3f}</p>\"\n",
        "        display(HTML(summary))\n",
        "        print(\"\\nNote: English words use a bigram model trained on the Brown corpus. Chinese words use jieba.\")\n"
      ],
      "metadata": {
        "id": "f6M8nqCIUWs0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 11: Launch the interface\n",
        "text_input.on_submit(on_submit)\n",
        "display(text_input, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802,
          "referenced_widgets": [
            "b693262f177b4ddba9ad3b7c11a4a270",
            "710778c9732b4e13968f70d03a8bd6ed",
            "0cbd76ece81f4cac9d95bf9302a53585",
            "a297b452d46748a1a92e9c44bdd790a0",
            "82ba355c90ed4c91ad00899e5d148a78"
          ]
        },
        "id": "tNqErPn0Ual3",
        "outputId": "c23b9b29-a361-4a6a-ffd5-22e8063f24e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='machinelearning正在重新定义教育healthcare和transportation领域的解决方案和效率', description='Input:', layout=Layout(w…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b693262f177b4ddba9ad3b7c11a4a270"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a297b452d46748a1a92e9c44bdd790a0"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}